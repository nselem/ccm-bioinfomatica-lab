{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sz7p_S_qnaqI",
        "outputId": "cc48edce-4d46-4085-dd48-522ae566a589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cargar datos\n",
        "data_Original_MinMaxScaler=pd.read_csv('/content/gdrive/MyDrive/CAMDA/dta_original_MinMaxScaler.tsv',sep=\"\\t\")\n",
        "data_Original_Normalizer=pd.read_csv('/content/gdrive/MyDrive/CAMDA/dta_original_Normalizer.tsv',sep=\"\\t\")\n",
        "data_Original_Power=pd.read_csv('/content/gdrive/MyDrive/CAMDA/dta_original_PowerTransformer.tsv',sep=\"\\t\")\n",
        "\n",
        "data_Original_Quantile=pd.read_csv('/content/gdrive/MyDrive/CAMDA/dta_original_QuantileTransformer.tsv',sep=\"\\t\")\n",
        "data_Original_RobustScaler=pd.read_csv('/content/gdrive/MyDrive/CAMDA/dta_original_RobustScaler.tsv',sep=\"\\t\")\n",
        "data_Original_StandardScaler=pd.read_csv('/content/gdrive/MyDrive/CAMDA/dta_original_StandardScaler.tsv',sep=\"\\t\")"
      ],
      "metadata": {
        "id": "V5MnsUJDn89o"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_Original_Quantile"
      ],
      "metadata": {
        "id": "Uy5duJrY272U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "creamos etiquetas y transponemos las matrices para separacion de entrenamiento y validación"
      ],
      "metadata": {
        "id": "t9s2EmIfXLad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ciudad_Original_MinMaxScaler=[]\n",
        "for i in data_Original_MinMaxScaler.keys()[1:]:\n",
        "  ciudad_Original_MinMaxScaler.append(i.split(\"_\")[-2])\n",
        "\n",
        "ciudad_Original_Normalizer=[]\n",
        "for i in data_Original_Normalizer.keys()[1:]:\n",
        "  ciudad_Original_Normalizer.append(i.split(\"_\")[-2])\n",
        "\n",
        "ciudad_Original_Power=[]\n",
        "for i in data_Original_Power.keys()[1:]:\n",
        "  ciudad_Original_Power.append(i.split(\"_\")[-2])\n",
        "\n",
        "ciudad_Original_Quantile=[]\n",
        "for i in data_Original_Quantile.keys()[1:]:\n",
        "  ciudad_Original_Quantile.append(i.split(\"_\")[-2])\n",
        "\n",
        "ciudad_Original_RobustScaler=[]\n",
        "for i in data_Original_RobustScaler.keys()[1:]:\n",
        "  ciudad_Original_RobustScaler.append(i.split(\"_\")[-2])\n",
        "\n",
        "ciudad_Original_StandardScaler=[]\n",
        "for i in data_Original_StandardScaler.keys()[1:]:\n",
        "  ciudad_Original_StandardScaler.append(i.split(\"_\")[-2])\n",
        "\"\"\"\n",
        "print(ciudadOQ)\n",
        "print(len(ciudadOQ))\n",
        "print(dataOQ.shape)\n",
        "\"\"\"\n",
        "\n",
        "X_Original_MinMaxScaler =np.transpose(data_Original_MinMaxScaler.iloc[:,1:])\n",
        "y_Original_MinMaxScaler = ciudad_Original_MinMaxScaler\n",
        "\n",
        "X_Original_Normalizer =np.transpose(data_Original_Normalizer.iloc[:,1:])\n",
        "y_Original_Normalizer = ciudad_Original_Normalizer\n",
        "\n",
        "X_Original_Power =np.transpose(data_Original_Power.iloc[:,1:])\n",
        "y_Original_Power = ciudad_Original_Power\n",
        "\n",
        "X_Original_Quantile =np.transpose(data_Original_Quantile.iloc[:,1:])\n",
        "y_Original_Quantile = ciudad_Original_Quantile\n",
        "\n",
        "X_Original_RobustScaler =np.transpose(data_Original_RobustScaler.iloc[:,1:])\n",
        "y_Original_RobustScaler = ciudad_Original_RobustScaler\n",
        "\n",
        "X_Original_StandardScaler =np.transpose(data_Original_StandardScaler.iloc[:,1:])\n",
        "y_Original_StandardScaler = ciudad_Original_StandardScaler"
      ],
      "metadata": {
        "id": "eqnQ0XxspRmd"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#separación de los datos\n",
        "semilla=35\n",
        "X_Original_MinMaxScaler_train, X_Original_MinMaxScaler_test, y_Original_MinMaxScaler_train, y_Original_MinMaxScaler_test = train_test_split(X_Original_MinMaxScaler, y_Original_MinMaxScaler,test_size = 0.15, stratify=y_Original_MinMaxScaler, random_state=semilla)\n",
        "X_Original_Normalizer_train, X_Original_Normalizer_test, y_Original_Normalizer_train, y_Original_Normalizer_test = train_test_split(X_Original_Normalizer, y_Original_Normalizer,test_size = 0.15, stratify=y_Original_Normalizer, random_state=semilla)\n",
        "X_Original_Power_train, X_Original_Power_test, y_Original_Power_train, y_Original_Power_test = train_test_split(X_Original_Power, y_Original_Power,test_size = 0.15, stratify=y_Original_Power, random_state=semilla)\n",
        "X_Original_Quantile_train, X_Original_Quantile_test, y_Original_Quantile_train, y_Original_Quantile_test = train_test_split(X_Original_Quantile, y_Original_Quantile,test_size = 0.15, stratify=y_Original_Quantile, random_state=semilla)\n",
        "X_Original_RobustScaler_train, X_Original_RobustScaler_test, y_Original_RobustScaler_train, y_Original_RobustScaler_test = train_test_split(X_Original_RobustScaler, y_Original_RobustScaler,test_size = 0.15, stratify=y_Original_RobustScaler, random_state=semilla)\n",
        "X_Original_StandardScaler_train, X_Original_StandardScaler_test, y_Original_StandardScaler_train, y_Original_StandardScaler_test = train_test_split(X_Original_StandardScaler, y_Original_StandardScaler,test_size = 0.15, stratify=y_Original_StandardScaler, random_state=semilla)"
      ],
      "metadata": {
        "id": "fUg1Dk3cqk-9"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Random forest ***"
      ],
      "metadata": {
        "id": "dvCWLlVTXbez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trees=500\n",
        "pine= 99"
      ],
      "metadata": {
        "id": "-BbeH757v2UJ"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "forest= RandomForestClassifier(n_estimators=trees, random_state=pine, min_samples_split=9, max_depth= 25)\n",
        "forest_Original_MinMaxScaler=forest.fit(X_Original_MinMaxScaler_train, y_Original_MinMaxScaler_train)\n",
        "\n",
        "forest= RandomForestClassifier(n_estimators=trees, random_state=pine, min_samples_split=9, max_depth= 25)\n",
        "forest_Original_Normalizer=forest.fit(X_Original_Normalizer_train, y_Original_Normalizer_train)\n",
        "\n",
        "forest= RandomForestClassifier(n_estimators=trees, random_state=pine, min_samples_split=9, max_depth= 25)\n",
        "forest_Original_Power=forest.fit(X_Original_Power_train, y_Original_Power_train)\n",
        "\n",
        "forest= RandomForestClassifier(n_estimators=trees, random_state=pine, min_samples_split=9, max_depth= 25)\n",
        "forest_Original_Quantile=forest.fit(X_Original_Quantile_train, y_Original_Quantile_train)\n",
        "\n",
        "forest= RandomForestClassifier(n_estimators=trees, random_state=pine, min_samples_split=9, max_depth= 25)\n",
        "forest_Original_RobustScaler=forest.fit(X_Original_RobustScaler_train, y_Original_RobustScaler_train)\n",
        "\n",
        "forest= RandomForestClassifier(n_estimators=trees, random_state=pine, min_samples_split=9, max_depth= 25)\n",
        "forest_Original_StandardScaler=forest.fit(X_Original_StandardScaler_train, y_Original_StandardScaler_train)"
      ],
      "metadata": {
        "id": "VRUh8PJgp5u8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy of forest_Original_MinMaxScaler on test set: {:.3f}\".format(forest_Original_MinMaxScaler.score(X_Original_MinMaxScaler_test, y_Original_MinMaxScaler_test)))\n",
        "print(\"Accuracy of forest_Original_Normalizer on test set: {:.3f}\".format(forest_Original_Normalizer.score(X_Original_Normalizer_test, y_Original_Normalizer_test)))\n",
        "print(\"Accuracy of forest_Original_Power on test set: {:.3f}\".format(forest_Original_Power.score(X_Original_Power_test, y_Original_Power_test)))\n",
        "print(\"Accuracy of forest_Original_Quantile on test set: {:.3f}\".format(forest_Original_Quantile.score(X_Original_Quantile_test, y_Original_Quantile_test)))\n",
        "print(\"Accuracy of forest_Original_RobustScaler on test set: {:.3f}\".format(forest_Original_RobustScaler.score(X_Original_RobustScaler_test, y_Original_RobustScaler_test)))\n",
        "print(\"Accuracy of forest_Original_StandardScaler on test set: {:.3f}\".format(forest_Original_StandardScaler.score(X_Original_StandardScaler_test, y_Original_StandardScaler_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9qs64qzzR1P",
        "outputId": "dd64fae5-2363-49af-f2f7-a2358f3054e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of forest_Original_MinMaxScaler on test set: 0.884\n",
            "Accuracy of forest_Original_Normalizer on test set: 0.814\n",
            "Accuracy of forest_Original_Power on test set: 0.860\n",
            "Accuracy of forest_Original_Quantile on test set: 0.884\n",
            "Accuracy of forest_Original_RobustScaler on test set: 0.884\n",
            "Accuracy of forest_Original_StandardScaler on test set: 0.884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"f1 score of forest_Original_MinMaxScaler on test set: {:.3f}\".format(metrics.f1_score(y_Original_MinMaxScaler_test,forest_Original_MinMaxScaler.predict(X_Original_Power_test), average=\"weighted\")))\n",
        "print(\"f1 score of forest_Original_Normalizer on test set: {:.3f}\".format(metrics.f1_score(y_Original_Normalizer_test,forest_Original_Normalizer.predict(X_Original_Normalizer_test), average=\"weighted\")))\n",
        "print(\"f1 score of forest_Original_RobustScaler on test set: {:.3f}\".format(metrics.f1_score(y_Original_RobustScaler_test,forest_Original_RobustScaler.predict(X_Original_RobustScaler_test), average=\"weighted\")))\n",
        "print(\"f1 score of forest_Original_Quantile on test set: {:.3f}\".format(metrics.f1_score(y_Original_Quantile_test,forest_Original_Quantile.predict(X_Original_Quantile_test), average=\"weighted\")))\n",
        "print(\"f1 score of forest_Original_Power on test set: {:.3f}\".format(metrics.f1_score(y_Original_Power_test,forest_Original_Power.predict(X_Original_Power_test), average=\"weighted\")))\n",
        "print(\"f1 score of forest_Original_StandardScaler on test set: {:.3f}\".format(metrics.f1_score(y_Original_StandardScaler_test,forest_Original_StandardScaler.predict(X_Original_StandardScaler_test), average=\"weighted\")))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b954K8GFzv9z",
        "outputId": "f0ed1e0b-0606-471a-ed0b-574d46180791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score of forest_Original_MinMaxScaler on test set: 0.490\n",
            "f1 score of forest_Original_Normalizer on test set: 0.782\n",
            "f1 score of forest_Original_RobustScaler on test set: 0.880\n",
            "f1 score of forest_Original_Quantile on test set: 0.880\n",
            "f1 score of forest_Original_Power on test set: 0.859\n",
            "f1 score of forest_Original_StandardScaler on test set: 0.880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multi-layer Perceptron**"
      ],
      "metadata": {
        "id": "VfK4ZhOMXoYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hls=(2000,250,)\n",
        "MLP=MLPClassifier(hidden_layer_sizes=hls)\n",
        "MLP_Original_MinMaxScaler=MLP.fit(X_Original_MinMaxScaler_train, y_Original_MinMaxScaler_train)\n",
        "\n",
        "MLP=MLPClassifier(hidden_layer_sizes=hls)\n",
        "MLP_Original_Normalizer=MLP.fit(X_Original_Normalizer_train, y_Original_Normalizer_train)\n",
        "\n",
        "MLP=MLPClassifier(hidden_layer_sizes=hls)\n",
        "MLP_Original_Power=MLP.fit(X_Original_Power_train, y_Original_Power_train)\n",
        "\n",
        "MLP=MLPClassifier(hidden_layer_sizes=hls)\n",
        "MLP_Original_Quantile=MLP.fit(X_Original_Quantile_train, y_Original_Quantile_train)\n",
        "\n",
        "MLP=MLPClassifier(hidden_layer_sizes=hls)\n",
        "MLP_Original_RobustScaler=MLP.fit(X_Original_RobustScaler_train, y_Original_RobustScaler_train)\n",
        "\n",
        "MLP=MLPClassifier(hidden_layer_sizes=hls)\n",
        "MLP_Original_StandardScaler=MLP.fit(X_Original_StandardScaler_train, y_Original_StandardScaler_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ar-LlLi6AHdh",
        "outputId": "280c164a-5401-4c22-db94-3163d3d0f004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy of MLP_Original_MinMaxScaler on test set: {:.3f}\".format(MLP_Original_MinMaxScaler.score(X_Original_MinMaxScaler_test, y_Original_MinMaxScaler_test)))\n",
        "print(\"Accuracy of MLP_Original_Normalizer on test set: {:.3f}\".format(MLP_Original_Normalizer.score(X_Original_Normalizer_test, y_Original_Normalizer_test)))\n",
        "print(\"Accuracy of MLP_Original_Power on test set: {:.3f}\".format(MLP_Original_Power.score(X_Original_Power_test, y_Original_Power_test)))\n",
        "print(\"Accuracy of MLP_Original_Quantile on test set: {:.3f}\".format(MLP_Original_Quantile.score(X_Original_Quantile_test, y_Original_Quantile_test)))\n",
        "print(\"Accuracy of MLP_Original_RobustScaler on test set: {:.3f}\".format(MLP_Original_RobustScaler.score(X_Original_RobustScaler_test, y_Original_RobustScaler_test)))\n",
        "print(\"Accuracy of MLP_Original_StandardScaler on test set: {:.3f}\".format(MLP_Original_StandardScaler.score(X_Original_StandardScaler_test, y_Original_StandardScaler_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xYBAe3IBS67",
        "outputId": "8b10f8a1-b209-4c98-feb5-d75bcf6e78e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of MLP_Original_MinMaxScaler on test set: 0.791\n",
            "Accuracy of MLP_Original_Normalizer on test set: 0.628\n",
            "Accuracy of MLP_Original_Power on test set: 0.581\n",
            "Accuracy of MLP_Original_Quantile on test set: 0.837\n",
            "Accuracy of MLP_Original_RobustScaler on test set: 0.651\n",
            "Accuracy of MLP_Original_StandardScaler on test set: 0.651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"f1 score of MLP_Original_MinMaxScaler on test set: {:.3f}\".format(metrics.f1_score(y_Original_MinMaxScaler_test,MLP_Original_MinMaxScaler.predict(X_Original_Power_test), average=\"weighted\")))\n",
        "print(\"f1 score of MLP_Original_Normalizer on test set: {:.3f}\".format(metrics.f1_score(y_Original_Normalizer_test,MLP_Original_Normalizer.predict(X_Original_Normalizer_test), average=\"weighted\")))\n",
        "print(\"f1 score of MLP_Original_RobustScaler on test set: {:.3f}\".format(metrics.f1_score(y_Original_RobustScaler_test,MLP_Original_RobustScaler.predict(X_Original_RobustScaler_test), average=\"weighted\")))\n",
        "print(\"f1 score of MLP_Original_Quantile on test set: {:.3f}\".format(metrics.f1_score(y_Original_Quantile_test,MLP_Original_Quantile.predict(X_Original_Quantile_test), average=\"weighted\")))\n",
        "print(\"f1 score of MLP_Original_Power on test set: {:.3f}\".format(metrics.f1_score(y_Original_Power_test,MLP_Original_Power.predict(X_Original_Power_test), average=\"weighted\")))\n",
        "print(\"f1 score of MLP_Original_StandardScaler on test set: {:.3f}\".format(metrics.f1_score(y_Original_StandardScaler_test,MLP_Original_StandardScaler.predict(X_Original_StandardScaler_test), average=\"weighted\")))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jP7U0QM0Bjr4",
        "outputId": "e6002047-4dd3-43aa-8ce7-dd3d675a4079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score of MLP_Original_MinMaxScaler on test set: 0.569\n",
            "f1 score of MLP_Original_Normalizer on test set: 0.615\n",
            "f1 score of MLP_Original_RobustScaler on test set: 0.648\n",
            "f1 score of MLP_Original_Quantile on test set: 0.840\n",
            "f1 score of MLP_Original_Power on test set: 0.585\n",
            "f1 score of MLP_Original_StandardScaler on test set: 0.657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a usar un PCA para reducir parametros de Quantile y reentrenaremos el bosque"
      ],
      "metadata": {
        "id": "Ca6JF5vKa_y_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "TmJEVetobbTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "componentes_PCA=30\n",
        "pca=PCA(n_components=componentes_PCA)\n",
        "X_Original_Quantile_PCA=pca.fit_transform(X_Original_Quantile)\n",
        "X_Original_Quantile_train_PCA, X_Original_Quantile_test_PCA, y_Original_Quantile_train_PCA, y_Original_Quantile_test_PCA = train_test_split(X_Original_Quantile_PCA, y_Original_Quantile,test_size = 0.15, stratify=y_Original_Quantile, random_state=semilla)\n"
      ],
      "metadata": {
        "id": "MpNnjHkob35w"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forest= RandomForestClassifier(n_estimators=trees, random_state=pine, min_samples_split=9, max_depth= 25)\n",
        "forest_Original_Quantile_PCA=forest.fit(X_Original_Quantile_train_PCA, y_Original_Quantile_train)"
      ],
      "metadata": {
        "id": "N-zL6yPvcoSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy of forest_Original_Quantile_PCA on test set: {:.3f}\".format(forest_Original_Quantile_PCA.score(X_Original_Quantile_test_PCA, y_Original_Quantile_test)))\n",
        "print(\"f1 score of forest_Original_Quantile_PCA on test set: {:.3f}\".format(metrics.f1_score(y_Original_Quantile_test,forest_Original_Quantile_PCA.predict(X_Original_Quantile_test_PCA), average=\"weighted\")))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t9DAr4EdGNY",
        "outputId": "94801996-eadd-4ee3-89af-e5eca5468d00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of forest_Original_Quantile_PCA on test set: 0.837\n",
            "f1 score of forest_Original_Quantile_PCA on test set: 0.817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Intentemos con un TSNE en lugar de PCA"
      ],
      "metadata": {
        "id": "oxNKi7C2kF5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "componentes_TSNE=4\n",
        "tsne=TSNE(n_components=componentes_TSNE, method=\"exact\")\n",
        "\n",
        "X_Original_Quantile_TSNE=tsne.fit_transform(X_Original_Quantile)\n",
        "X_Original_Quantile_train_TSNE, X_Original_Quantile_test_TSNE, y_Original_Quantile_train_TSNE, y_Original_Quantile_test_TSNE = train_test_split(X_Original_Quantile_TSNE, y_Original_Quantile,test_size = 0.15, stratify=y_Original_Quantile, random_state=semilla)\n",
        "\n",
        "forest= RandomForestClassifier(n_estimators=trees, random_state=pine, min_samples_split=9, max_depth= 25)\n",
        "forest_Original_Quantile_TSNE=forest.fit(X_Original_Quantile_train_TSNE, y_Original_Quantile_train)\n",
        "\n",
        "print(\"Accuracy of forest_Original_Quantile_TSNE on test set: {:.3f}\".format(forest_Original_Quantile_TSNE.score(X_Original_Quantile_test_TSNE, y_Original_Quantile_test)))\n",
        "print(\"f1 score of forest_Original_Quantile_TSNE on test set: {:.3f}\".format(metrics.f1_score(y_Original_Quantile_test,forest_Original_Quantile_TSNE.predict(X_Original_Quantile_test_TSNE), average=\"weighted\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF3FmJK_kLze",
        "outputId": "a8e79864-3fe9-44e5-a131-413eb4012107"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of forest_Original_Quantile_TSNE on test set: 0.744\n",
            "f1 score of forest_Original_Quantile_TSNE on test set: 0.759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extra Trees Clasifier"
      ],
      "metadata": {
        "id": "0SFvmvbHpT7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "extra_trees=300\n",
        "extra=ExtraTreesClassifier(n_estimators=extra_trees, random_state=pine, min_samples_split=9, max_depth= 25)\n",
        "extra_Original_Quantile=extra.fit(X_Original_Quantile_train, y_Original_Quantile_train)\n",
        "print(\"Accuracy of extra_Original_Quantile on test set: {:.3f}\".format(extra_Original_Quantile.score(X_Original_Quantile_test, y_Original_Quantile_test)))\n",
        "print(\"f1 score of extra_Original_Quantile on test set: {:.3f}\".format(metrics.f1_score(y_Original_Quantile_test,extra_Original_Quantile.predict(X_Original_Quantile_test), average=\"weighted\")))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLzF6IETpTTv",
        "outputId": "698b4280-1cfa-418d-da1a-403c2da3f54e"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of extra_Original_Quantile on test set: 0.860\n",
            "f1 score of extra_Original_Quantile on test set: 0.852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RF_predict=forest_Original_Quantile.predict(X_Original_Quantile_test)\n",
        "ET_predict=extra_Original_Quantile.predict(X_Original_Quantile_test)\n",
        "RFPCA_predict=forest_Original_Quantile_PCA.predict(X_Original_Quantile_test_PCA)\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "enc.fit(np.array(y_Original_Quantile_train).reshape((len(y_Original_Quantile_train),1)))\n",
        "\n",
        "RF_train=enc.transform(np.array(forest_Original_Quantile.predict(X_Original_Quantile_train)).reshape(len(y_Original_Quantile_train),1))\n",
        "ET_train=enc.transform(np.array(extra_Original_Quantile.predict(X_Original_Quantile_train)).reshape(len(y_Original_Quantile_train),1))\n",
        "RFPCA_train=enc.transform(np.array(forest_Original_Quantile_PCA.predict(X_Original_Quantile_train_PCA)).reshape(len(y_Original_Quantile_train_PCA),1))\n",
        "\n",
        "\n",
        "\n",
        "X_INPUT_train=np.concatenate([np.array(RF_train),np.array(ET_train),np.array(RFPCA_train)], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "MLP_INPUT=MLPClassifier()\n",
        "MLP_INPUT.fit(X_INPUT_train, y_Original_Quantile_train)\n",
        "\n",
        "INPUT=np.concatenate((RF,ET,RFPCA), axis=1)\n",
        "\n",
        "print(MLP_Original_Quantile.predict(RF))\n",
        "INPUT.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "7L5M74sXxeOQ",
        "outputId": "1833645b-0f06-43e3-abd2-b30bb0af7ee7"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-128-2b7a8f62ac5f>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mX_INPUT_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRF_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mET_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRFPCA_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: zero-dimensional arrays cannot be concatenated"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.concatenate((np.array(RF_train),np.array(ET_train),np.array(RFPCA_train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "Ov0jvPN48Fe0",
        "outputId": "3652276c-9617-48bf-bdc6-38c2e6e30dc1"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-131-daede9fc82bf>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRF_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mET_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRFPCA_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: zero-dimensional arrays cannot be concatenated"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(RF_train).shape\n",
        "#print(ET_train.shape)\n",
        "#print(RFPCA_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-QCOKnX97Kr",
        "outputId": "9c8fbf23-5a02-4703-bc28-2d85934e5d23"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "75ti8yInDdtO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}